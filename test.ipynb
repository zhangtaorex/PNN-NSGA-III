{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from scipy.linalg import LinAlgError\n",
    "from scipy.spatial.distance import cdist\n",
    "import pandas as pd\n",
    "from modelsgelu import *\n",
    "import numpy as np\n",
    "import optuna\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_62448\\1812033132.py:10: FutureWarning: load_study(): Please give all values as keyword arguments. See https://github.com/optuna/optuna/issues/3324 for details.\n",
      "  load_study = optuna.study.load_study(\"selus\", \"sqlite:///optuna.db\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "parallel_net(\n",
       "  (skin_embedding_tabel): Embedding(5, 4096)\n",
       "  (stringer_embedding_tabel): Embedding(5, 4096)\n",
       "  (Bi_lstm_skin): LSTM(4096, 2048, batch_first=True, bidirectional=True)\n",
       "  (Bi_lstm_stringer): LSTM(4096, 1024, batch_first=True, bidirectional=True)\n",
       "  (attention_skin): SelfAttention(\n",
       "    (linear_q): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (linear_k): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (linear_v): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "  )\n",
       "  (attention_stringer): SelfAttention(\n",
       "    (linear_q): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "    (linear_k): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "    (linear_v): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "  )\n",
       "  (feedforward_skin): FeedForward(\n",
       "    (w_1): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (w_2): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (feedforward_stringer): FeedForward(\n",
       "    (w_1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (w_2): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sub_skin_1): SublayerConnection(\n",
       "    (norm): LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sub_skin_2): SublayerConnection(\n",
       "    (norm): LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sub_stringer_1): SublayerConnection(\n",
       "    (norm): LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sub_stringer_2): SublayerConnection(\n",
       "    (norm): LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (skin_features_layer): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "  (stringer_features_layer): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (fc0): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=8, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "    (3): SELU()\n",
       "    (4): Linear(in_features=4, out_features=2, bias=True)\n",
       "    (5): SELU()\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Linear(in_features=8, out_features=16, bias=True)\n",
       "    (3): SELU()\n",
       "    (4): Linear(in_features=16, out_features=32, bias=True)\n",
       "    (5): SELU()\n",
       "    (6): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (7): SELU()\n",
       "    (8): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (9): SELU()\n",
       "    (10): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (11): SELU()\n",
       "    (12): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (13): SELU()\n",
       "    (14): Linear(in_features=512, out_features=4096, bias=True)\n",
       "    (15): SELU()\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=22528, out_features=4096, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (3): SELU()\n",
       "    (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (5): SELU()\n",
       "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (7): SELU()\n",
       "    (8): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (9): SELU()\n",
       "    (10): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (11): SELU()\n",
       "    (12): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (13): SELU()\n",
       "    (14): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (15): SELU()\n",
       "    (16): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (17): SELU()\n",
       "    (18): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (19): SELU()\n",
       "    (20): Linear(in_features=8, out_features=4, bias=True)\n",
       "    (21): SELU()\n",
       "    (22): Linear(in_features=4, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)       # Current CPU\n",
    "    torch.cuda.manual_seed(seed)  # Current GPU\n",
    "    np.random.seed(seed)          # Numpy module\n",
    "    random.seed(seed)             # Python random module\n",
    "    torch.backends.cudnn.benchmark = False    # Close optimization\n",
    "    torch.backends.cudnn.deterministic = True # Close optimization\n",
    "    torch.cuda.manual_seed_all(seed) # All GPU (Optional)\n",
    "seed_everything(1)\n",
    "load_study = optuna.study.load_study(\"selus\", \"sqlite:///optuna.db\")\n",
    "best_params = load_study.best_params\n",
    "model_dim = best_params[\"model_dim\"]\n",
    "# batch_size = best_params[\"batch_size\"]\n",
    "batch_size = 128\n",
    "lr = best_params[\"lr\"]\n",
    "skin_hidden_size = best_params[\"skin_hidden_size\"]\n",
    "stringer_hidden_size = best_params[\"stringer_hidden_size\"]\n",
    "otherfeatures_hidden_size = best_params[\"otherfeatures_hidden_size\"]\n",
    "net = parallel_net(model_dim,skin_hidden_size,stringer_hidden_size,otherfeatures_hidden_size)\n",
    "bucking_loads = np.zeros(1)\n",
    "preds = np.zeros(1)\n",
    "model_dict = torch.load(\"./checkpoint5.pt\")\n",
    "net.load_state_dict(model_dict)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134.700</td>\n",
       "      <td>7.700</td>\n",
       "      <td>4.200</td>\n",
       "      <td>4.200</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.369</td>\n",
       "      <td>1590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145.000</td>\n",
       "      <td>9.500</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101.700</td>\n",
       "      <td>6.000</td>\n",
       "      <td>2.400</td>\n",
       "      <td>2.400</td>\n",
       "      <td>2.400</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121.000</td>\n",
       "      <td>5.820</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126.100</td>\n",
       "      <td>11.200</td>\n",
       "      <td>5.460</td>\n",
       "      <td>5.460</td>\n",
       "      <td>5.460</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>131.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>4.500</td>\n",
       "      <td>4.500</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0.290</td>\n",
       "      <td>1544.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77.460</td>\n",
       "      <td>77.460</td>\n",
       "      <td>4.150</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.626</td>\n",
       "      <td>0.030</td>\n",
       "      <td>1655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>155.000</td>\n",
       "      <td>12.100</td>\n",
       "      <td>4.400</td>\n",
       "      <td>4.400</td>\n",
       "      <td>3.200</td>\n",
       "      <td>0.248</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>127.700</td>\n",
       "      <td>9.670</td>\n",
       "      <td>6.500</td>\n",
       "      <td>6.500</td>\n",
       "      <td>3.600</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1520.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>131.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>6.410</td>\n",
       "      <td>6.410</td>\n",
       "      <td>6.410</td>\n",
       "      <td>0.380</td>\n",
       "      <td>1522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>135.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>45.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>164.000</td>\n",
       "      <td>12.800</td>\n",
       "      <td>4.500</td>\n",
       "      <td>4.500</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.320</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>38.000</td>\n",
       "      <td>8.270</td>\n",
       "      <td>4.140</td>\n",
       "      <td>4.140</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>195.000</td>\n",
       "      <td>14.600</td>\n",
       "      <td>7.500</td>\n",
       "      <td>7.500</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>161.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>6.100</td>\n",
       "      <td>6.100</td>\n",
       "      <td>6.100</td>\n",
       "      <td>0.260</td>\n",
       "      <td>1580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>137.900</td>\n",
       "      <td>8.960</td>\n",
       "      <td>7.100</td>\n",
       "      <td>7.100</td>\n",
       "      <td>6.210</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>145.000</td>\n",
       "      <td>10.300</td>\n",
       "      <td>5.300</td>\n",
       "      <td>5.275</td>\n",
       "      <td>3.950</td>\n",
       "      <td>0.301</td>\n",
       "      <td>1590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>160.000</td>\n",
       "      <td>8.970</td>\n",
       "      <td>6.210</td>\n",
       "      <td>6.210</td>\n",
       "      <td>3.450</td>\n",
       "      <td>0.016</td>\n",
       "      <td>2700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>80.000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>6.480</td>\n",
       "      <td>5.100</td>\n",
       "      <td>4.070</td>\n",
       "      <td>0.060</td>\n",
       "      <td>1610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>150.150</td>\n",
       "      <td>12.020</td>\n",
       "      <td>6.110</td>\n",
       "      <td>6.110</td>\n",
       "      <td>6.110</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1790.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>58.600</td>\n",
       "      <td>58.600</td>\n",
       "      <td>3.060</td>\n",
       "      <td>3.060</td>\n",
       "      <td>3.060</td>\n",
       "      <td>0.048</td>\n",
       "      <td>1510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>136.500</td>\n",
       "      <td>10.100</td>\n",
       "      <td>3.975</td>\n",
       "      <td>3.975</td>\n",
       "      <td>3.975</td>\n",
       "      <td>0.270</td>\n",
       "      <td>1530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>101.000</td>\n",
       "      <td>16.700</td>\n",
       "      <td>3.400</td>\n",
       "      <td>3.400</td>\n",
       "      <td>3.400</td>\n",
       "      <td>0.270</td>\n",
       "      <td>1530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>103.800</td>\n",
       "      <td>6.550</td>\n",
       "      <td>2.900</td>\n",
       "      <td>2.900</td>\n",
       "      <td>2.900</td>\n",
       "      <td>0.280</td>\n",
       "      <td>1530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>57.765</td>\n",
       "      <td>53.686</td>\n",
       "      <td>3.065</td>\n",
       "      <td>3.065</td>\n",
       "      <td>3.065</td>\n",
       "      <td>0.048</td>\n",
       "      <td>1510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>119.600</td>\n",
       "      <td>9.200</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.270</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>125.000</td>\n",
       "      <td>11.300</td>\n",
       "      <td>5.430</td>\n",
       "      <td>5.430</td>\n",
       "      <td>3.979</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>210.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>7.450</td>\n",
       "      <td>7.450</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>138.000</td>\n",
       "      <td>8.960</td>\n",
       "      <td>7.100</td>\n",
       "      <td>7.100</td>\n",
       "      <td>6.200</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>131.000</td>\n",
       "      <td>10.300</td>\n",
       "      <td>6.900</td>\n",
       "      <td>6.200</td>\n",
       "      <td>6.200</td>\n",
       "      <td>0.220</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>207.000</td>\n",
       "      <td>20.700</td>\n",
       "      <td>6.900</td>\n",
       "      <td>6.900</td>\n",
       "      <td>4.100</td>\n",
       "      <td>0.300</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>155.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>155.000</td>\n",
       "      <td>12.100</td>\n",
       "      <td>4.400</td>\n",
       "      <td>4.400</td>\n",
       "      <td>3.200</td>\n",
       "      <td>0.248</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1      2      3      4      5       6\n",
       "0   134.700   7.700  4.200  4.200  2.500  0.369  1590.0\n",
       "1   145.000   9.500  5.000  5.000  3.500  0.300  1450.0\n",
       "2   101.700   6.000  2.400  2.400  2.400  0.300  1700.0\n",
       "3   121.000   5.820  4.000  4.000  4.000  0.300  1580.0\n",
       "4   126.100  11.200  5.460  5.460  5.460  0.300  1560.0\n",
       "5    25.000  25.000  3.000  3.000  3.000  0.300  2200.0\n",
       "6   131.000   8.000  4.500  4.500  3.500  0.290  1544.0\n",
       "7    77.460  77.460  4.150  3.625  3.626  0.030  1655.0\n",
       "8   155.000  12.100  4.400  4.400  3.200  0.248  1600.0\n",
       "9   127.700   9.670  6.500  6.500  3.600  0.300  1520.7\n",
       "10  131.000  13.000  6.410  6.410  6.410  0.380  1522.0\n",
       "11  135.000  10.000  5.000  5.000  5.000  0.300  1600.0\n",
       "12   45.000  10.000  5.000  5.000  5.000  0.300  2000.0\n",
       "13  164.000  12.800  4.500  4.500  2.500  0.320  1800.0\n",
       "14   38.000   8.270  4.140  4.140  4.000  0.250  1900.0\n",
       "15  195.000  14.600  7.500  7.500  5.000  0.300  1400.0\n",
       "16  161.000   9.000  6.100  6.100  6.100  0.260  1580.0\n",
       "17  137.900   8.960  7.100  7.100  6.210  0.300  1600.0\n",
       "18  145.000  10.300  5.300  5.275  3.950  0.301  1590.0\n",
       "19  160.000   8.970  6.210  6.210  3.450  0.016  2700.0\n",
       "20   80.000  80.000  6.480  5.100  4.070  0.060  1610.0\n",
       "21  150.150  12.020  6.110  6.110  6.110  0.300  1790.0\n",
       "22   58.600  58.600  3.060  3.060  3.060  0.048  1510.0\n",
       "23  136.500  10.100  3.975  3.975  3.975  0.270  1530.0\n",
       "24  101.000  16.700  3.400  3.400  3.400  0.270  1530.0\n",
       "25  103.800   6.550  2.900  2.900  2.900  0.280  1530.0\n",
       "26   57.765  53.686  3.065  3.065  3.065  0.048  1510.0\n",
       "27  119.600   9.200  4.000  4.000  4.000  0.270  1800.0\n",
       "28  125.000  11.300  5.430  5.430  3.979  0.300  1478.0\n",
       "29  210.000  45.000  7.450  7.450  4.000  0.300  1500.0\n",
       "30  138.000   8.960  7.100  7.100  6.200  0.300  1600.0\n",
       "31  131.000  10.300  6.900  6.200  6.200  0.220  1500.0\n",
       "32  207.000  20.700  6.900  6.900  4.100  0.300  2000.0\n",
       "33  155.000   8.000  4.000  4.000  4.000  0.300  1600.0\n",
       "34  155.000  12.100  4.400  4.400  3.200  0.248  1600.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Material_lab = pd.read_csv(\"./ml.csv\",header=None)\n",
    "Material_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = np.array([4]*28+[175]*2+[35]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub = np.array([0]*28+[125]*2+[1]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvar = len(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4,   2,   1, ..., 141,  11,  12],\n",
       "       [  3,   0,   3, ..., 150,  33,  16],\n",
       "       [  3,   4,   0, ..., 138,  23,  14],\n",
       "       ...,\n",
       "       [  2,   0,   3, ..., 125,  32,   1],\n",
       "       [  0,   4,   1, ..., 141,   5,  27],\n",
       "       [  0,   4,   4, ..., 147,   3,  10]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop = np.random.randint(ub,lb+1 ,(100,nvar))\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_seq = pop[:,:16]\n",
    "stringer_seq = pop[:,16:28]\n",
    "other_feas = np.zeros_like(a=0,shape=(100, 14),dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_seq_length = np.zeros(100)\n",
    "strigner_seq_length = np.zeros(100)\n",
    "rou_skin = np.zeros(100)\n",
    "rou_stringer = np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100): # type: ignore\n",
    "    skin_seq_ = skin_seq[i,:]\n",
    "    decode_skin = np.array([x for x in skin_seq_ if x!=0])\n",
    "    skin_seq_length[i] = len(decode_skin)\n",
    "    decode_skin = np.pad(decode_skin, (0,16-len(decode_skin)), \"constant\", constant_values=0)\n",
    "    skin_seq[i] = decode_skin\n",
    "    stringer_seq_ = stringer_seq[i,:]\n",
    "    decode_stringer = np.array([x for x in stringer_seq_ if x!=0])\n",
    "    strigner_seq_length[i] = len(decode_stringer)\n",
    "    decode_stringer = np.pad(decode_stringer, (0,12-len(decode_stringer)), \"constant\", constant_values=0)\n",
    "    stringer_seq[i] = decode_stringer\n",
    "    skin_material = pop[:,28:][i,2]\n",
    "    stringer_material = pop[:,28:][i,3]\n",
    "    rou_skin[i] = Material_lab.iloc[skin_material-1][6]\n",
    "    rou_stringer[i] = Material_lab.iloc[stringer_material-1][6]\n",
    "    thickness = np.array([pop[:,28:][i,0]/1000 ,pop[:,28:][i,1]/1000])\n",
    "    skin_material = np.array(Material_lab.iloc[skin_material-1][0:6])\n",
    "    stringer_material = np.array(Material_lab.iloc[stringer_material-1][0:6])\n",
    "    other_fea = np.concatenate([skin_material,stringer_material,thickness])  \n",
    "    other_feas[i] = other_fea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, 1, 3, 3, 2, 4, 1, 2, 3, 1, 4, 4, 2, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skin_seq[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determing_seq(seq):\n",
    "    pops = seq.shape[0]\n",
    "    index = np.zeros(pops,dtype=np.int32)\n",
    "    for i in range(pops):\n",
    "        seq_ = seq[i]\n",
    "        decode_seq = np.array([x for x in seq_ if x!=0])\n",
    "        seq_len = len(decode_seq)\n",
    "        index[i] = 0\n",
    "        \n",
    "        if sum(decode_seq==2) != sum(decode_seq==4) or sum(decode_seq==1)<0.1*seq_len or sum(decode_seq==2)<0.1*seq_len or sum(decode_seq==3)<0.1*seq_len or sum(decode_seq==4)<0.1*seq_len or decode_seq[-3] == decode_seq[-2] or decode_seq[-3] == decode_seq[-1]:\n",
    "            index[i] = 1\n",
    "\n",
    "        # for j in range(seq_len-1):\n",
    "        #     if abs(decode_seq[j]-decode_seq[j+1]) == 2:\n",
    "        #         index[i] = 1\n",
    "            \n",
    "        # for k in range(seq_len-4):\n",
    "        #      if decode_seq[k] == decode_seq[k+1] or decode_seq[k] == decode_seq[k+2] or decode_seq[k] == decode_seq[k+3] or decode_seq[k] == decode_seq[k+4]:\n",
    "        #          index[i] = 1\n",
    "            \n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "determing_seq(skin_seq)\n",
    "determing_seq(stringer_seq)\n",
    "index = np.logical_or(determing_seq(stringer_seq),determing_seq(skin_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_feas[0,-2]\n",
    "True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass = (0.479+0.000057692*rou_stringer*strigner_seq_length*2*other_feas[:,-1]+0.000422451*rou_skin*skin_seq_length*2*other_feas[:,-2]).reshape(-1,1)\n",
    "mass[index]+=10000\n",
    "mass\n",
    "len(mass)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_seq = torch.tensor(skin_seq, dtype=torch.int32)\n",
    "stringer_seq = torch.tensor(stringer_seq, dtype=torch.int32)\n",
    "other_feas = torch.tensor(other_feas,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = -1*net(skin_seq, stringer_seq, other_feas).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = np.concatenate([mass, preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7839372160000004"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass = (0.479+0.000057692*1600*10*2*0.14*4+0.000422451*1600*12*2*0.14)\n",
    "mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0338406400000002"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.000422451*1600*12*2*0.14\n",
    "0.000057692*1600*10*2*0.14*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
